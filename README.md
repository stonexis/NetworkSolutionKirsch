# ***Генерация полей напряжений в пластине с отверстием (PyTorch энкодер-декодер)***

## Краткое описание:

Данный проект демонстрирует применение нейросетевой модели типа энкодер-декодер для предсказания распределения напряжений в пластине с круглым отверстием при одноосном растяжении.
Модель обучается на синтетических данных, полученных из аналитического решения задачи (формулы Кирша для бесконечной пластинки с отверстием), и позволяет по заданным геометрическим параметрам и граничным условиям предсказывать компоненты тензора напряжений.

## Цели проекта:

Основная цель – показать, что свёрточная нейросеть энкодер-декодер способна по геометрическим параметрам (радиус отверстия, размеры пластины) и граничным условиям (величина приложенного одноосного напряжения) предсказать поле напряжений в упругой пластине с отверстием.
Проект иллюстрирует возможность заменить трудоёмкие аналитические или численные решения набыстродействующей нейросетевой моделью, обученной воспроизводить известное аналитическое решение Кирша для распределения напряжений вокруг круглого отверстия.
Таким образом, достигается демонстрация того, как методы машинного обучения могут применяться в задачах механики для приближённого вычисления напряжений по заданной конфигурации.

## Структура проекта:

Проект состоит из следующих основных файлов и компонентов:

```gendata.hpp / gendata.tpp``` – шаблонные функции на C++ для генерации синтетических данных. 
Содержат реализацию функции generate_data для создания выборки, а также функции для вычисления аналитического поля напряжений (UniaxialStress, формулы Кирша) 
и формирования тензоров входных параметров ```gen_mesh_with_params``` и выходных напряжений ```gen_sigma_field```.

```KirchCourse.ipynb``` – Jupyter ноутбук на Python, содержащий код обучения нейросети на сгенерированных данных. 
В ноутбуке реализована модель нейросети (свёрточный энкодер-декодер на PyTorch), код для загрузки данных ```.npy```, нормализации, обучение модели на тренировочной выборке с мониторингом ошибки на валидационной выборке, 
а также визуализация результатов сравнения предсказанных полей напряжений с эталонными (аналитическими) значениями.

## Генерация данных (C++)

```g++ -std=c++17 main.cpp -o generate_data -lz```

После выполнения в текущей директории появятся файлы сгенерированных данных:

```train_input_params.npy``` и ```train_target_fields.npy``` – входные параметры и целевые поля напряжений для обучающей выборки (по умолчанию 20 000 образцов).

```val_input_params.npy``` и ```val_target_fields.npy``` – данные для валидационной выборки (2 000 образцов).

```test_input_params.npy``` и ```test_target_fields.npy``` – данные для тестовой выборки (10 образцов для примера).

### Структура данных: 

Входные данные представляют собой тензоры размерности ```(N, 4, 128, 128)```, где N – число семплов.
 4 канала входных данных соответствуют координате x, координате y точки сетки, значению радиуса отверстия a (одинаковое во всей карте) и значению приложенного напряжения P (также константная карта).
 Выходные (целевые) данные – тензоры размерностью ```(N, 3, 128, 128)```, содержащие компоненты напряжений: sigma_xx, sigma_yy и sigma_xy в каждой точке сетки.
 Внутри отверстия (точки, расстояние r от центра меньше a) аналитическое решение не определено, и значения напряжений помечены как NaN; в коде они заменяются на 0 перед обучением.

 ## Обучение модели (Python/PyTorch)

 ### Модель: 
 
 Нейросеть ```ParamCoordUNet``` – это сверточный автоэнкодер без skip-коннектов, принимающий на вход тензор размером ```4×128×128``` (4 канала входных карт, см. выше) и выдающий тензор ```3×128×128``` (предсказанные компоненты ```sigma_xx, sigma_yy, sigma_xy```).
 Архитектура включает несколько слоёв ```Conv2d``` с понижением разрешения до ```7×7``` и симметричный декодер с ```ConvTranspose2d``` для восстановления разрешения.
 Функция потерь – среднеквадратичная ошибка (MSE) между предсказанной и эталонной картами напряжений.

 ### Процесс обучения: 
 
 Обучение проводится на GPU. В ноутбуке по умолчанию задано 50 эпох обучения с начальным шагом оптимизатора ```Adam 1e-3``` (используется ```ReduceLROnPlateau``` для снижения шага при плато ошибки).
 После каждой эпохи выводятся значения ошибки на обучающем и валидационном наборах. В конце обучения ошибка на валидации достигает порядка ```3.9×10^-4``` (в нормированных единицах) при обучении на заданной выборке, что свидетельствует о высокой точности модели (порядка долей процента относительно максимальных значений напряжений).

 ### Сохранение и использование модели: 
 В ноутбуке присутствует закомментированный фрагмент сохранения весов модели ```(torch.save(... 'model_weights.pt'))```.
 При необходимости вы можете раскомментировать его, чтобы сохранить обученную модель.
 Далее модель может быть загружена и использована для предсказания на новых данных без повторного обучения (в ноутбуке показано примерное использование – загрузка весов и прогноз на одном тестовом примере).

 ### Результаты и визуализация

 Пример сравнения предсказанных моделью и аналитических полей напряжений.
